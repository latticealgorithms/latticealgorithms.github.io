---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
title: Algorithms for lattice problems in NP \(\cap\) CoNP
---

<head>
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>

<head>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "%LINEBREAKS" },
                        webFont: "%FONT"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "%LINEBREAKS" },
              font: "%FONT"},
        NativeMML: {scale: 100},
        TeX: { inlineMath: [['$', '$'], ['\\(', '\\)']],
          equationNumbers: {autoNumber: "%AUTONUMBER"},
          MultLineWidth: "%MULTLINEWIDTH",
          TagSide: "%TAGSIDE",
          TagIndent: "%TAGINDENT",
        }
    });
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>


<div style="display:none">
\(
\newcommand{\minGS}{\min_i \|\vb_i^*\|}
\newcommand{\eps}{\varepsilon}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vb}{\mathbf{b}}
\newcommand{\vc}{\mathbf{c}}
\newcommand{\ve}{\mathbf{e}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vt}{\mathbf{t}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\matA}{\mathbf A}
\newcommand{\matAt}{\tilde{\mathbf A}}
\newcommand{\matB}{\mathbf B}
\newcommand{\matC}{\{\mathbf C}\} 
\newcommand{\matG}{\{\mathbf G}\} 
\newcommand{\matI}{\{\mathbf I}\} 
\newcommand{\matM}{\{\mathbf M}\} 
\newcommand{\matR}{\{\mathbf R}\} 
\newcommand{\matW}{\mathbf{W}}
\newcommand{\calP}{\mathcal P} 
\newcommand{\per}{p}
\newcommand{\perL}{\per(L)}
\newcommand{\fgr}{r}
\newcommand{\fgrL}{\fgr(L)}
\newcommand{\vol}{\operatorname{vol}}
\newcommand{\rndL}{\tilde{L}}
\newcommand{\LWE}{\operatorname{LWE}}
\newcommand{\BDD}{\operatorname{BDD}}
\newcommand{\CVP}{\operatorname{CVP}}
\newcommand{\SVP}{\operatorname{SVP}}
\newcommand{\SIVP}{\operatorname{SIVP}}
\newcommand{\GapCVP}{\operatorname{GapCVP}}
\newcommand{\GapSVP}{\operatorname{GapSVP}}
\newcommand{\GapSVL}{\operatorname{GapSVL}}
\newcommand{\BitDecomp}{\operatorname{BitDecomp}}
\newcommand{\Flatten}{\operatorname{Flatten}}
\newcommand{\Powersoftwo}{\operatorname{Powersof2}}
\newcommand{\<}{\langle}
\renewcommand{\>}{\rangle}
\newcommand{\pfactor}{\gamma}
\newcommand{\dfactor}{\Gamma}
\newcommand{\vD}{\mathbf{\Delta}}
\newcommand{\qq}{q}
\newcommand{\qqn}{q(n)}
\newcommand{\pv}{\mathbf{v}}
\newcommand{\dv}{\mathbf{w}}
\newcommand{\pL}{L}
\newcommand{\pB}{\mathbf{B}}
\newcommand{\dL}{L^*}
\newcommand{\dB}{\mathbf{D}}
\newcommand{\Gdist}[1]{G(#1)}
\newcommand{\Gsup}[1]{|G(#1)\rangle}
\newcommand{\flattenlen}{\{k \log q}\}
\newcommand{\klogq}{\{k \log q}\}
\newcommand{\flatc}{\overline{\vc}}
\newcommand{\flatC}{\overline{\matC}}
\)
</div>



<div id="orgfbfbc13" class="figure">
<p><img src="assets/img/xyz.svg" alt="xyz.svg" class="org-svg" align="right" style="width: 40%" />
</p>
</div>

<p>
This site is dedicated to organizing and presenting what is known about the class of lattice problems that may have efficient algorithms.  It is intended to be a living document that is updated as information comes in and as time permits.  
</p>

<p>
The goal is to advance research on lattice algorithms.  There are some impediments to working in this area such as its breadth, its increasingly technical nature, notational and language differences, the amount of folklore, and so on.  This site provides an opportunity to have everything relevant to lattice algorithms written in one place, from one point of view, with consistent terminology, and targeted for a broader audience.  Making it available to a broader audience can help build confidence that certain ranges may be difficult to solve.
</p>

<p>
Here is a picture from <a href="https://arxiv.org/2201.13450">arxiv.org/abs/2201.13450</a>:
</p>


<div id="org108cfbe" class="figure">
<p><img src="assets/img/pic-ranges.jpg" alt="pic-ranges.jpg" width="75%" style="margin-left: auto; margin-right: auto;" />
</p>
</div>

<p>
The right three regions represent NP intersect CoNP, but most work has focused on the left two regions.  From an algorithms perspective, the natural approach is to push from the right side where algorithms are known.  Let's do that and determine where the boundaries are.
</p>

<p>
To participate send email to {{ site.email }}.  Suggestions about all topics related to this site are welcome.  This includes technical information, how to organize topics, how to visualize what is known, anything at all.  Help can be public, private, or anoymous.  
</p>

<div id="outline-container-orgd4b485c" class="outline-2">
<h2 id="orgd4b485c"><span class="section-number-2">1.</span> Nomenclature for this website</h2>
<div class="outline-text-2" id="text-1">
<ol class="org-ol">
<li>Problems with efficient algorithms may be called easy, easy to solve, poly time, or polynomial time.</li>
<li>Problems where no efficient algorithm are known may be called open, open problems,  hard, or hard cases.  These really are open problems and should not be confused with NP-hard problems which are hard in a fundamentally different way.</li>
<li>\(\GapSVP\), the problem of deciding if a given lattice has a Shortest Vector Length lower or much larger than a given number, will often be called \(\GapSVL\) to better reflect the underlying problem.  So \(\GapSVP=\GapSVL\) here.</li>
<li>Subexponential has a few different meanings depending on the context.  Here subexponential in \(n\) will typically mean a function of the form \(2^{n^\epsilon}\), for \(\epsilon <1\).  An example is \(2^{\sqrt{n}}\).</li>
<li>For a basis \(\pB\) of a lattice \(\pL\).  Basis dependent quantities like \(\|\vb_1\|\), the length of the first column of \(\pB\), will be in terms of the basis, and basis independent quantities like \(\lambda_1(\pL)\) will be in terms of the lattice.  For example, if \(\vb_1\neq 0\), then the inequality \(\lambda_1(\pL) \leq \|\vb_1\|\) indicates that one quantity is basis dependent and the other is not.</li>
</ol>
</div>
</div>

<div id="outline-container-org41d66f2" class="outline-2">
<h2 id="org41d66f2"><span class="section-number-2">2.</span> \(\GapSVP_\gamma\) status</h2>
<div class="outline-text-2" id="text-2">
<p>
\(\GapSVP_\gamma\) is the decision version of approxmating the length of the shortest vector in a lattice.  Given a basis \(\pB\) of an \(n\)-dimensional integer lattice \(\pL\) and a number \(d\in \R\), decide if \(\lambda_1(\pL) \leq d\) or \(d\gamma < \lambda_1(\pL)\).  This the case studied in [Reg09].
</p>
<ol class="org-ol">
<li>As a function of the dimension \(n\):
<ul class="org-ul">
<li>\(\gamma(n) = 2^{n/2}\) is poly time.</li>
<li>\(\gamma(n) = 2^{n \log \log n/\log n}\) is poly time.</li>
</ul></li>
<li>The determinant of \(L\) provides information, where \(\gamma = 2^{\sqrt{\log \det(L)}}\) is easy.</li>
<li>More can be said by looking at the period \(\perL\) of the lattice \(\pL\) and the finite abelian group rank \(\fgr\) of \(\pL \bmod \perL\).  Given a lattice \(L\), these two quantities are easy to compute.  Then
<ul class="org-ul">
<li>\(\gamma(n) = 2^{\sqrt{\fgr \log \perL}}\) is poly time.
<ul class="org-ul">
<li>For example, for the class of lattices \(L\) that have \(\fgr = \sqrt{n}\) and \(\perL = 2^{n^{1/4}}\), approxmation factor \(\gamma = 2^{n^{3/8}}\) has an efficient algorithm.</li>
</ul></li>
</ul></li>
</ol>
</div>
</div>

<div id="outline-container-org7658c57" class="outline-2">
<h2 id="org7658c57"><span class="section-number-2">3.</span> Upcoming topics</h2>
<div class="outline-text-2" id="text-3">
<ol class="org-ol">
<li>What is NP intersect CoNP (i.e., NP \(\cap\) CoNP) and why is it relevant here?</li>
<li>What does it take to establish a belief that no efficient algorithm exists for a computational problem?  It's not easy.  For example, who has worked on it?  For how long?  How much expertise is necessary, and who has it?  What kind of incentive is there to work on it?  Are people actively discouraged from working on it for various reasons?  What are the answers to these questions for factoring and LWE?</li>
<li>Does the worst-to-average case reduction from lattice problems to LWE have a complexity flavor, or is it more like discrete log?</li>
<li>What is the right parameter set to use for measuring progress in lattice algorithms?  The dimension has long been the focus but with progress stuck for so long is that a good idea?</li>
</ol>
</div>
</div>

<div id="outline-container-org38d52ab" class="outline-2">
<h2 id="org38d52ab"><span class="section-number-2">4.</span> Questions</h2>
<div class="outline-text-2" id="text-4">
<ol class="org-ol">
<li>Why does <a href="https://latticechallenge.org">latticechallenge.org</a> only have \(q\) = prime and not the power-of-two case?  What about \(q=n^2\)?</li>
<li>Which subexponential approximation factor assumptions have been made for fully-homomorphic encryption, and how do they relate to the recent algorithms?</li>
</ol>
</div>
</div>

<div id="outline-container-orgaf33bb9" class="outline-2">
<h2 id="orgaf33bb9"><span class="section-number-2">5.</span> Open Problems</h2>
<div class="outline-text-2" id="text-5">
<ol class="org-ol">
<li>The driving question, way off in the distance: does a polynomial-time algorithm exist for solving any lattice problems with polynomial approximation factor?</li>
<li>As a more reasonable starting point, which lattices problems can be solved for subexponential approximation factors?</li>
<li>Which problems are easier to solve for special case lattices such as ideal lattices?</li>
</ol>
</div>
</div>

<div id="outline-container-org8dff594" class="outline-2">
<h2 id="org8dff594"><span class="section-number-2">6.</span> Links to lattice-based cryptography</h2>
<div class="outline-text-2" id="text-6">
<p>
A lot of amazing tools have been developed in lattice-based cryptography over the last couple of decades.  Perhaps they can help with algorithms for lattice problems in NP \(\cap\) CoNP also.  There will be some translation necessary.
</p>
</div>
</div>

<div id="outline-container-org3088ef4" class="outline-2">
<h2 id="org3088ef4"><span class="section-number-2">7.</span> Reductions are the tool to compare the relative computational difficulty of problems</h2>
<div class="outline-text-2" id="text-7">
<p>
In computer science there are not good tools to prove that efficient algorithms don't exist to solve a problem.  Most problem in NP either have a polynomial-time algorithm or they can be shown to be NP-complete.  NP-complete are not generally believed to have efficient classical or quantum algorithms, but they are not the topic of this site.  Here the focus in on problems that are in NP$&cap;$CoNP.  This includes the class of polynomial-time solvable problems.
</p>

<p>
A problem \(A\) reduces to a problem \(B\), written \(A \leq B\), if an algorithm for \(B\) can be used to solve problem \(A\).  A reduction is an algorithm and therefore can be specified by its resources.  A reduction might be computable computable \(\leq_c\), polynomial time \(\leq\), randomized \(\leq_r\), or quantum \(\leq_Q\).  Reductions can be used for both algorithms and for hardness.  Here \(\leq\) with no subscript will denote polynomial-time because it will be used the most.
</p>

<ul class="org-ul">
<li>If \(A \leq B\) and there is a polynomial-time algorithm for \(B\), then there is a polynomial-time algorithm for \(A\) because polynomials compose.</li>
<li>If \(A \leq B\) and there is no polynomial-time algorithm for \(A\), then there is no polynomial-time algorithm for \(B\).</li>
</ul>
</div>

<div id="outline-container-orgbbc515c" class="outline-3">
<h3 id="orgbbc515c"><span class="section-number-3">7.1.</span> Simple examples using polynomial-time reductions and algorithms but avoiding necessary technicality:</h3>
<div class="outline-text-3" id="text-7-1">
<ol class="org-ol">
<li>Break RSA mod \(N\) \(\leq\) factor \(N\).
Therefore, if there is an algorithm for factoring then there is an algorithm to break RSA.</li>
<li>Solve SVP \(\leq_Q\) break LWE.
Therefore, if there is no quantum algorithm for SVP, then there is no quantum algorithm for breaking LWE.</li>
<li>\(\BDD \leq \SVP\) when the approximation factor is something.</li>
</ol>
</div>
</div>
</div>


<div id="outline-container-orgc356995" class="outline-2">
<h2 id="orgc356995"><span class="section-number-2">8.</span> \(\BDD\) is not \(\LWE\)</h2>
<div class="outline-text-2" id="text-8">
</div>
<div id="outline-container-org0955fbe" class="outline-3">
<h3 id="org0955fbe"><span class="section-number-3">8.1.</span> Bounded Distance Decoding (\(\BDD\)) and Learning With Errors (\(\LWE\)) are not the same problem.  They are related in important ways, but they are also different in important ways.</h3>
<div class="outline-text-3" id="text-8-1">
<p>
One might say that \(\BDD \leq \LWE \leq \BDD\) to have a high-level understanding of the relationship, but what's missing in that statement are the parameters and problem definitions that give the relationships the necessary meaning.
</p>

<ol class="org-ol">
<li>The theoretical connection \(\BDD \leq \LWE\) is used to conclude that an algorithm for \(\LWE\) can be used to construct a quantum algorithm for \(\BDD\).</li>

<li>Concrete security involves choosing key sizes for implementations.  This uses the more the direct \(\LWE\) \(\leq\) \(\BDD\) reduction, similar to Break RSA \(\leq\) Factoring.  In this case a \(\BDD\) algorithm of the right parameters can be used to solve LWE, because after an \(\LWE\) instance is chosen and fixed, it is then a \(\BDD\) instance.  Running \(\BDD\) algorithms on those instances is used to understand how well algorithms perform on LWE.</li>
</ol>
</div>
</div>


<div id="outline-container-org64b4788" class="outline-3">
<h3 id="org64b4788"><span class="section-number-3">8.2.</span> The classical reduction from \(\BDD\) to \(\LWE\)</h3>
<div class="outline-text-3" id="text-8-2">
<p>
The first step of the worst-case to average-case reduction in [Reg09] is a classical reduction from \(\BDD\) to \(\LWE\).  Here is a sketch.
</p>

<p>
Let \(\qqn\) and \(\alpha(n)\) be functions such that \(2\sqrt{n} \leq \qqn\alpha(n)\).<br />
Let \(m(n)\) be a polynomial in \(n\).<br />
Input: \(\pB\) for lattice \(\pL\) of dimension \(n\), target vector \(\vt = \pB\cdot \vs + \vD\), \(\|\vD\| \leq \alpha(n) \lambda_1(\pL)\).
</p>
<ol class="org-ol">
<li>Repeat until \(\vs\) is computed:
<ol class="org-ol">
<li>Sample \(\dv_1,\ldots, \dv_{m(n)} \in \dL\) according to a Gaussian with parameter \(\varphi_{3n}(\dL)\).</li>
<li>For \(i = 1, \ldots , m(n)\):
<ol class="org-ol">
<li>Compute \(\va_i = \dv_i \cdot \pB \bmod \qqn\).</li>
<li>Compute \(b_i = \dv_i \cdot \vt \bmod \qqn\).</li>
</ol></li>
<li>Call the \(\LWE_{n,\qqn,\alpha}\) oracle with \((\va_1,b_1), \ldots, (\va_{m(n)}, b_{m(n)})\) and get the low-order bits the secret coefficient vector, namely \(\vs_\ell = \vs \bmod \qqn\), where \(\vs = \vs_h \qqn + \vs_\ell\).</li>
<li>Set \(\vt := \frac{\vt - \pB\cdot \vs_\ell}{\qqn} = \frac{\pB\cdot(\vs_h \qqn + \vs_\ell - \vs_\ell) + \vD}{\qqn} = \frac{\pB \cdot\vs_h\qqn}{\qqn} + \frac{\vD}{\qqn}\).</li>
</ol></li>
</ol>

<p>
Some differences between \(\BDD\) and \(\LWE\) can be seen in this reduction.  The lattice given as part of the \(\BDD\) input is any lattice.  The input to the \(\LWE\) problem has an associated random lattice that can be computed from the \(\va_i\)'s.  The classical hardness result for \(\LWE\) uses this part of the reduction and shows that if \(\LWE\) is solvable then it is possible to approximate length of a shortest vector of an arbitrary lattice.  In contrast, the length of a shortest vector in the associated \(\LWE\) lattice is easy to compute.  It ends up being long, which is can be useful.
</p>
</div>
</div>

<div id="outline-container-org1fc22ea" class="outline-3">
<h3 id="org1fc22ea"><span class="section-number-3">8.3.</span> The quantum reduction from \(\varphi_0(\dL)\)-\(\SIVP\) to \(\LWE_{n,\qqn,\alpha(n)}\).</h3>
<div class="outline-text-3" id="text-8-3">
<ul class="org-ul">
<li><p>
Some notation for quantum samples
</p>

<p>
To describe the steps of the quantum reduction in a somewhat concise way the notion of quantum sampling can be used to replace the classical samples.  For a given distribution, a quantum sample is a quantum state whose measurement results in a sample from the same distribution.  
</p>

<p>
For this reduction, let \(\Gdist{\dL,r}\) be the discrete gaussian distribution on \(\dL\) with standard deviation \(r\).  This is called \(D_{\dL,r}\) in [Reg09].  A quantum sample of this distribution is the superposition \(\Gsup{\dL,r} = \sum_{\dv\in\dL} \sqrt{p_\dv} |\dv\>\), where \(p_\dv\) is the probability of measuring \(\dv\) from \(\Gdist{\dL,r}\).  Measuring \(\Gsup{\dL,r}\) destroys the state, so the algorithm will need to create a quantum sample in each of \(m(n)\) registers, resulting in the state \(\Gsup{\dL,r}^{\otimes m(n)}\).  This is tensor product notation for the state \(\Gsup{\dL,r}\Gsup{\dL,r} \cdots \Gsup{\dL,r}\), \(m(n)\) times.  To summarize the notation, given the state \(\Gsup{\dL,r}^{\otimes m(n)}\), it can be measured any time to produce \(m(n)\) independent samples from \(\Gdist{\dL,r}\).
</p></li>

<li>For \(\SIVP\) the reduction will compute \(\Gsup{\dL, \varphi_0(\dL)}^{\otimes m(n)}\), where \(\varphi_0(\dL) = \frac{\sqrt{2n}}{\alpha(n)}\eta_\epsilon(\dL)\).  The approximation factor is therefore not just a function of the dimension \(n\) but also of the input lattice itself.  This quantum sample is enough to solve \(\SIVP\).  Measuring the state will result in samples where \(n\) can be selected such that the length is at most \(\sqrt{n} \varphi_0(\dL)\).</li>

<li><p>
Reduction sketch
</p>

<p>
Let \(\qqn\) and \(\pfactor(n)\) be functions.<br />
Let \(m(n)\) be a polynomial in \(n\).<br />
Input: \(\pB\) for lattice \(\pL\) of dimension \(n\), target vector \(\vt = \pB\cdot \vs + \vD\), \(\|\vD\| \leq \pfactor(\dL) \lambda_1(\pL)\)
</p>
<ol class="org-ol">
<li>Compute \(\Gsup{\dL,\varphi_{3n}(\dL)}^{\otimes m(n)}\).</li>
<li>for \(i = 3n-1, 3n-2, \ldots, 0\):
<ol class="org-ol">
<li>Measure the state \(\Gsup{\dL,\varphi_{i+1}^{}(\dL)}^{\otimes m(n)}\) to generate \(m(n)\) samples \(\dv_1, \ldots, \dv_{m(n)}\) from \(\Gdist{\dL, \varphi_{i+1}(\dL)}\).</li>
<li>For \(i = 1,\ldots, m(n)\):
<ol class="org-ol">
<li>Compute \(\va_i = \dv_i \cdot \pB \bmod \qqn\).</li>
<li>For \(j = 1, \ldots, m(n)\):
<ol class="org-ol">
<li>In new registers, compute \(\sum_{\pv \in \pL} \rho_?(\pv) \sum_{\vt} \rho_?(\vt)|\pv+\vt\>|\vt\>|0\>^{\otimes m(n)}\).</li>
<li>Compute each \(b_i^{(\vt)} = \dv_i \cdot \vt \bmod 1\), giving
\[\sum_{\pv \in \pL} \rho_?(\pv) \sum_{\vt} \rho_?(\vt)|\pv+\vt\> |\vt\>|b_1^{(\vt)},\ldots,b_{m(n)}^{(\vt)}\>.\]</li>
<li>Compute \(\pfactor\)-\(\BDD\) using \(\LWE\) on \((\va_1, b_1^{(\vt)}), \ldots,(\va_{m(n)}, b_{m(n)}^{(\vt)})\) to erase \(\vt\), giving 
\[\sum_{\pv \in \pL} \rho_?(\pv) \sum_{\vt} \rho_?(\vt)|\pv+\vt\>|0\>|b_1^{(\vt)},\ldots,b_{m(n)}^{(\vt)}\>.\]</li>
<li>Uncompute each \(b_i^{(\vt)}\) by computing \(\dv_i \cdot (\pv+\vt) = \dv_i \cdot \pv + \dv_i \cdot \vt \bmod 1 =  b_i^{(\vt)}\), subtracting, and running backwards to get
\[\sum_{\pv \in \pL} \rho_?(\pv) \sum_{\vt} \rho_?(\vt)|\pv+\vt\>|0\>|0\>^{\otimes m(n)}.\]</li>

<li>Compute \(F_{q(n)}\) to get \(\Gsup{\dL,\varphi_i(\dL)}\).</li>
</ol></li>
</ol></li>
</ol></li>
<li>Output \(\Gsup{\dL,\varphi_0(\dL)}^{\otimes m(n)}\).</li>
</ol></li>
</ul>



<div id="orgb2fd12f" class="figure">
<p><img src="assets/img/reductionblock.svg" alt="reductionblock.svg" class="org-svg" align="right" style="width: 70%" />
</p>
</div>
</div>

<div id="outline-container-org3fd05a7" class="outline-4">
<h4 id="org3fd05a7"><span class="section-number-4">8.3.1.</span> Technical references:</h4>
<div class="outline-text-4" id="text-8-3-1">
</div>
<ol class="org-ol">
<li><a id="orgac640e3"></a>[Reg05]: \(\BDD \leq \LWE\) for \(q(n)=2^{3n}\).<br /></li>
<li><a id="orgfcbe34c"></a>[Pei09]: \(\GapSVL \leq \BDD\)<br /></li>
<li><a id="org4df0f82"></a>[LM09]: \(\BDD \leq \SVP\)<br /></li>
<li><a id="orge1c2e1a"></a>[BLPRS13]: ?<br /></li>
<li><a id="org35c4a92"></a>[EH21/EEH22]: \(\BDD \leq_Q \LWE\).<br /></li>
</ol>
</div>
</div>

<div id="outline-container-org5610714" class="outline-3">
<h3 id="org5610714"><span class="section-number-3">8.4.</span> </h3>
</div>
</div>

<div id="outline-container-orgb34f0e3" class="outline-2">
<h2 id="orgb34f0e3"><span class="section-number-2">9.</span> Lattice parameters</h2>
<div class="outline-text-2" id="text-9">
</div>
<div id="outline-container-orgcf176ef" class="outline-3">
<h3 id="orgcf176ef"><span class="section-number-3">9.1.</span> Using the dimension \(n = \dim(L)\) might prevent progress.</h3>
<div class="outline-text-3" id="text-9-1">
<p>
Running times and approximation factors for lattices have typically been measured as a function of their dimension \(n\).  It makes for nice, clean statements.  For example, LLL is a polynomial-time algorithm to compute vectors within a \(2^n\) factor of the shortest vector.  Babai's algorithm takes also takes a vector in space and computes a close lattice vector that is within a \(2^n\) factor of the closest.  These approximation factors are exponential in the dimension \(n\).  It can be said that there is no efficient algorithm known to achieve subexponential or polynomial approximation factors.  See, for example <a href="https://cseweb.ucsd.edu/classes/fa21/cse206A-a/LecLLL.pdf">Remark 2</a> and <a href="https://web.eecs.umich.edu/~cpeikert/pubs/lattice-survey.pdf">Page 8, Algorithms and Complexity</a>.  Furthermore, this has been the case for decades.  There are also classes of lattice problems that are NP-hard but are not relevant here because they are not in CoNP.
</p>

<p>
The typical way to handle being stuck is to break the problem down into special cases to try to make progress.  For lattices, perhaps measuring everything in terms of the dimension is preventing progress.  For example, there might be an efficient algorithm for problems with a subexponential approximation factor, like \(2^\sqrt{n}\), but it's too hard to find it all at once, just like it's too hard to climb a mountain in one giant step.  
</p>

<p>
As one of the L's in LLL once told me, when everyone is stuck on a problem, it is a form of art to back off the full problem and solve a subcase that is both nontrivial and solvable.  
</p>
</div>
</div>

<div id="outline-container-orgb48e18a" class="outline-3">
<h3 id="orgb48e18a"><span class="section-number-3">9.2.</span> Another possibility: lattice periodicity \(\perL\) and finite group rank \(\fgrL\)</h3>
<div class="outline-text-3" id="text-9-2">
<p>
Without loss of generality, a lattice can be specified by a basis \(\matB\) and numbers \(\per_1(L),\cdots,\per_n(L)\) with the following properties.  Let \(\perL\) be the minimum number such that \(\perL \Z^n \leq L\).
</p>
<ol class="org-ol">
<li>For each \(i\), \(\per_i(L)\cdot \vb_i\) is a multiple of \(\perL\),</li>
<li>\(1= \per_{n}(L)\ \big|\ \per_{n-1}(L)\ \big|\ \cdots\ \big|\  \per_1(L)\ \big|\ \perL\).</li>
</ol>
<p>
In particular, \(L \bmod \perL\) is a finite abelian group, and columns \(\vb_{\fgrL+1},\ldots,\vb_n\) are \(\vzero \bmod \perL\).  For \(\SVP\) and \(\CVP\) those columns do not provide extra information.
</p>
</div>
</div>
</div>

<div id="outline-container-org66309f2" class="outline-2">
<h2 id="org66309f2"><span class="section-number-2">10.</span> The classical theoretical justification for LWE</h2>
<div class="outline-text-2" id="text-10">
<p>
Let \(q(n) = 2^{3n}\).
</p>

<p>
To understand the basis for \(\LWE_{n,n^c}\), the input to \(\GapSVL\) and \(\BDD\) includes a lattice \(L\) of dimension \(\sqrt{n}\).
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">\(\LWE_{n,n^c} \leftrightarrow \LWE_{\sqrt{n},2^n}\)</td>
<td class="org-left">As a function of the  worst-case dimension \(n\), period \(q(n)\), and dimension \(m(n)\) of the associated \(\LWE\) lattice \(\rndL\), approximating the length of the shortest vector of randomly selected lattices \(\rndL\) can be done since, with high probability, \(\delta \sqrt{m(n)} \det(\rndL)^{1/n} \leq \lambda_1(\rndL) \leq \sqrt{m(n)}\det(\rndL)^{1/n} = \sqrt{m(n)}q(n)^{1-n/m(n)}\) for a constant \(\delta\).</td>
</tr>

<tr>
<td class="org-left">\(\Bigg\uparrow\)</td>
</tr>

<tr>
<td class="org-left">\(\BDD\) dimension \(\sqrt{n}\)</td>
</tr>

<tr>
<td class="org-left">\(\Bigg\uparrow  \quad i.e., \GapSVL \leq \BDD\)</td>
</tr>

<tr>
<td class="org-left">\(\GapSVL\) dimension \(\sqrt{n}\)</td>
<td class="org-left">Approximate the length of shortest vector a lattice \(L\) that us taken from a certain subset of \(n\)-dimensional lattices.</td>
</tr>
</tbody>
</table>

<div id="orge50f12b" class="figure">
<p><img src="assets/img/pillar.svg" alt="pillar.svg" class="org-svg" style="width: 30%" align="left" /> 
</p>
</div>

<p>
Notes:
</p>
<ol class="org-ol">
<li>\(\GapSVL\) is known as \(\GapSVP\) in the literature.  Here the name is changed for two reasons.  First is that it has a mnemonic meaning: the Shortest Vector Length.  Second, when referring to the problem as \(\GapSVP\), it is easy to miss the fact that \(\LWE\) is based on computing the length of a shortest vector, which may be much easier than computing a shortest vector.</li>
<li>\(\BDD \leq \LWE_{2^{3n}}\) is a special case in [Reg09].  It is used as a black box in [Pei09].</li>
<li>\(\GapSVL \leq \BDD\) is from [Pei09].</li>
</ol>
</div>
</div>

<div id="outline-container-org8cce417" class="outline-2">
<h2 id="org8cce417"><span class="section-number-2">11.</span> Ideas that may or may not work</h2>
<div class="outline-text-2" id="text-11">
<ol class="org-ol">
<li>Amplitude amplification on a state containing shapes around each lattice point.</li>
<li>Partition lattices in various ways to make progress.</li>
</ol>
</div>
</div>

<div id="outline-container-orgc5b2780" class="outline-2">
<h2 id="orgc5b2780"><span class="section-number-2">12.</span> Road blocks</h2>
<div class="outline-text-2" id="text-12">
</div>
<div id="outline-container-org785f889" class="outline-3">
<h3 id="org785f889"><span class="section-number-3">12.1.</span> Cannot do the following</h3>
<div class="outline-text-3" id="text-12-1">
<ol class="org-ol">
<li>Using FHE, given \(\matA, \matA\vs+\ve\), compute \(\matA', \matA'(q/2)\vs+\ve'\).</li>
</ol>
</div>
</div>

<div id="outline-container-org354cc75" class="outline-3">
<h3 id="org354cc75"><span class="section-number-3">12.2.</span> Besides not finding an algorithm yet, are there other ways to describe why the various problems might or might not have an efficient algorithm?</h3>
</div>
</div>


<div id="outline-container-org37e9c24" class="outline-2">
<h2 id="org37e9c24"><span class="section-number-2">13.</span> Some lattice facts to organize</h2>
<div class="outline-text-2" id="text-13">
</div>
<div id="outline-container-org71e6183" class="outline-3">
<h3 id="org71e6183"><span class="section-number-3">13.1.</span> Lattices and their duals</h3>
<div class="outline-text-3" id="text-13-1">
</div>
<div id="outline-container-org87daf36" class="outline-4">
<h4 id="org87daf36"><span class="section-number-4">13.1.1.</span> Lattices come in pairs \((L,L^*)\)</h4>
<div class="outline-text-4" id="text-13-1-1">
<ol class="org-ol">
<li>\(1 \leq \lambda_1(L) \cdot \lambda_n(L^*) \leq n\).</li>
<li>\(\eta_{\eps(n)}(L) \leq \frac{\sqrt{n}}{\lambda_1(L^*)}\), for \(\eps(n) = \frac{1}{2^n}\).</li>
<li>\(c\frac{\lambda_n(L)}{n} \leq c \frac{1}{\lambda_1(L^*)} \leq \eta_{\eps(n)}(L)\) for \(\eps(n) = o(1)\) and any constant \(c\).</li>
<li>For \(\vw = \va\matB^{-1} \in L^*, \vv = \matB \vc \in L\), \(\vw \cdot \vv = \va \cdot \vc\).</li>
</ol>
</div>
</div>
<div id="outline-container-orgf4bfe9a" class="outline-4">
<h4 id="orgf4bfe9a"><span class="section-number-4">13.1.2.</span> Dual problems, approximation factors</h4>
<div class="outline-text-4" id="text-13-1-2">
<ol class="org-ol">
<li>\(\SVP\) vs. \(\CVP\)</li>
<li>\(\GapSVL\) vs. \(\GapCVP\)</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org9e9f503" class="outline-3">
<h3 id="org9e9f503"><span class="section-number-3">13.2.</span> Other</h3>
<div class="outline-text-3" id="text-13-2">
</div>
<div id="outline-container-orga18fc94" class="outline-4">
<h4 id="orga18fc94"><span class="section-number-4">13.2.1.</span> \(\forall\) bases \(\matB\) of \(L\):</h4>
<div class="outline-text-4" id="text-13-2-1">
<ol class="org-ol">
<li>\(\minGS \leq \lambda_1(L)\).</li>
<li>\(\det(L) := \vol(\calP(\matB)) = \prod_i \|\vb_i^*\|\).</li>
<li>\(\det(L) \leq \prod_i \|\vb_i\|\).</li>
<li>\(\det(L) = \sqrt{\det(\matB^t\matB)}\), and for the full-rank case, \(\det(L) = |\!\det(\matB)|\).</li>
</ol>
</div>
</div>
<div id="outline-container-org0f47f69" class="outline-4">
<h4 id="org0f47f69"><span class="section-number-4">13.2.2.</span> Define \(\gamma\)-SVP for a number \(\gamma\), but \(\gamma\) is usually a monotonically increasing function of \(n\).</h4>
</div>
<div id="outline-container-orge1372a9" class="outline-4">
<h4 id="orge1372a9"><span class="section-number-4">13.2.3.</span> \(\GapSVP_\gamma\) given \((\matB,d)\)&#x2026;.</h4>
</div>
</div>
</div>
